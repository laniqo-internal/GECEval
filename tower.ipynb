{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "380580f1-a450-40c8-b438-1e56245bf78c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "28fd458b-709f-4b5c-8a69-effd49e047b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTS = {\n",
    "    \"en\": \"Edit the text for spelling and grammar mistakes. \" \\\n",
    "               + \"Do not paraphrase the text. Correct just evident mistakes. Do not explain anything. \" \\\n",
    "               + \"Do not change numbers to letters. Return only the corrected text. \" \\\n",
    "               + \"Example. Text: The modern techonlogy is better now than what it used to be. \" \\\n",
    "               + \"Correct text: The modern technology is better now than it used to be. \" \\\n",
    "               + \"Text: __TEXT_PLACEHOLDER__ Correct text: \",\n",
    "    \"de\": \"Bearbeiten Sie den Text auf Rechtschreib- und Grammatikfehler. \" \\\n",
    "               + \"Paraphrasieren Sie den Text nicht. Korrigieren Sie nur offensichtliche Fehler. Erklären Sie nichts. \" \\\n",
    "               + \"Ändern Sie keine Zahlen in Buchstaben. Geben Sie nur den korrigierten Text zurück. \" \\\n",
    "               + \"Beispiel. Text: Die moderne Technik ist heute besser als früher. \" \\\n",
    "               + \"Richtiger Text: Die moderne Technik ist heute besser als früher. \" \\\n",
    "               + \"Text: __TEXT_PLACEHOLDER__ Richtiger Text: \"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5d5ff7e5-272e-4b70-bf69-f8574c74262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModelGec:\n",
    "\n",
    "    def __init__(self, p, lang):\n",
    "        self.text_generation_pipeline = p\n",
    "        self.prompt_text = PROMPTS[lang]\n",
    "\n",
    "    def get_conversation_template(self, prompt):\n",
    "        return [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def get_prompt(self, text):\n",
    "        return self.prompt_text.replace(\"__TEXT_PLACEHOLDER__\", text)\n",
    "\n",
    "    def __call__(self, text, params, debug=False):\n",
    "        prompt = self.get_prompt(text)\n",
    "        messages = self.get_conversation_template(prompt)\n",
    "        inputs = self.text_generation_pipeline.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        outputs = self.text_generation_pipeline(inputs, **params)\n",
    "        if debug:\n",
    "            print(messages)\n",
    "            print()\n",
    "            print(inputs)\n",
    "            print()\n",
    "            print(outputs)\n",
    "            print()\n",
    "        return outputs[0][\"generated_text\"].lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2802d17a-d106-4d2e-98d0-c6e7d5bbd17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModelGecFactory:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model_cache = {}\n",
    "\n",
    "    def get_pipeline(self, model_name, torch_dtype, device):\n",
    "        if model_name in self.model_cache:\n",
    "            return self.model_cache[model_name]\n",
    "        else:\n",
    "            p = pipeline(\n",
    "                \"text-generation\", \n",
    "                model=model_name,\n",
    "                torch_dtype=torch_dtype,\n",
    "                device=device,\n",
    "            )\n",
    "            self.model_cache[model_name] = p\n",
    "            return p\n",
    "\n",
    "    def create(self, model_name, lang, torch_dtype=torch.bfloat16, device='cuda'):\n",
    "        p = self.get_pipeline(model_name, torch_dtype, device)\n",
    "        return LanguageModelGec(p, lang)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cce2a14-d186-4d42-9559-2bb4bb1cf54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gec_factory = LanguageModelGecFactory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b6955a6b-2afc-469b-ab31-eca747eea95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Unbabel/TowerInstruct-7B-v0.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "70596df4-7925-4cd1-9ad3-73f5cc7080b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LanguageModelGec at 0x7984363036d0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gec_factory.create(model_name, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a8d91881-ea3a-4068-a124-bc2385a7e20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unbabel/TowerInstruct-7B-v0.2': <transformers.pipelines.text_generation.TextGenerationPipeline at 0x7987a7e0d970>}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gec_factory.model_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c428244-15fc-4788-8481-d7de20444e48",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d0367dc7-5e0b-461c-9797-22492d2eab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"do_sample\": True,\n",
    "    \"repetition_penalty\": 1.18,\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"top_k\": 40,\n",
    "    \"top_p\": 0.1,\n",
    "    \"temperature\": 0.1,\n",
    "    \"return_full_text\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1a4d69-423d-433b-bc62-292253b8bb31",
   "metadata": {},
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74ce5246-209e-43e6-b479-203717eadd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "gec = gec_factory.create(model_name, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3b6d077-adde-491a-8ca3-b63921cfb53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Edit the text for spelling and grammar mistakes. Do not paraphrase the text. Correct just evident mistakes. Do not explain anything. Do not change numbers to letters. Return only the corrected text. Example. Text: The modern techonlogy is better now than what it used to be. Correct text: The modern technology is better now than it used to be. Text: It became scencial to do my homework. Correct text: '}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = gec.get_conversation_template(gec.get_prompt(\"It became scencial to do my homework.\"))\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "725929aa-56f4-497a-9d80-d1c18bd4766e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>user\\nEdit the text for spelling and grammar mistakes. Do not paraphrase the text. Correct just evident mistakes. Do not explain anything. Do not change numbers to letters. Return only the corrected text. Example. Text: The modern techonlogy is better now than what it used to be. Correct text: The modern technology is better now than it used to be. Text: It became scencial to do my homework. Correct text: <|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = gec.text_generation_pipeline.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd6e132e-71cd-482c-8834-010c63656ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = gec.text_generation_pipeline(inputs, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "009d608a-8f6a-44a3-b0cf-2e8827758e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': ' It has become essential to do my homework.'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fcbde69-120d-4214-8410-0a82f532f136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It has become essential to do my homework.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gec(\"It became scencial to do my homework.\", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fd205d-6022-492f-b068-07a1ec8325eb",
   "metadata": {},
   "source": [
    "### Experiments set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1b0bb808-468d-4957-9c4d-460b49473dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"geceval/data/raw/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "df2b26da-5a70-4ff1-9585-5a4462032217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(idx, lang):\n",
    "    base_path = DATA_PATH + lang + \"/\"\n",
    "    file_name = f\"correct_{idx}.txt\"\n",
    "    if os.path.exists(base_path + file_name):\n",
    "        with open(base_path + file_name) as f:\n",
    "            return file_name, f.read()\n",
    "    else:\n",
    "        file_name = \"in\" + file_name\n",
    "        with open(base_path + file_name) as f:\n",
    "            return file_name, f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ec2c4080-1ebc-4e5d-8bd8-752283c453bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_single_example(idx, lang):\n",
    "    file_name, file_content = read_text(idx, lang)\n",
    "    return {\n",
    "        \"file_name\": file_name,\n",
    "        \"original_text\": file_content,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a7819b7e-03f4-4ba8-a70a-c06027b734c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_examples(idxes, lang):\n",
    "    examples = []\n",
    "    for i in idxes:\n",
    "        examples.append(prepare_single_example(i, lang))\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ff026985-4134-4fd9-b97e-dd3c164ec720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(examples, gec, params):\n",
    "    for example in tqdm(examples):\n",
    "        if \"corrected_text\" not in example:\n",
    "            text = example[\"original_text\"]\n",
    "            example[\"corrected_text\"] = gec(text, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "07dd427c-ca0d-4e93-bf2a-d94f97d955a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_examples(examples, lang):\n",
    "    base_path = DATA_PATH + lang + \"/\"\n",
    "    for example in tqdm(examples):\n",
    "        file_name = example[\"file_name\"]\n",
    "        inference_file_name = example[\"file_name\"].replace(\".txt\", \"\") + \"_inference.txt\"\n",
    "        original_text = example[\"original_text\"]\n",
    "        corrected_text = example[\"corrected_text\"]\n",
    "\n",
    "        if not os.path.exists(base_path + file_name):\n",
    "            with open(base_path + file_name, 'w') as f:\n",
    "                f.write(original_text)\n",
    "        if not os.path.exists(base_path + inference_file_name):\n",
    "            with open(base_path + inference_file_name, 'w') as f:\n",
    "                f.write(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "10741381-1b8c-44d9-a5df-18bb9586870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# random.seed(23)\n",
    "# indexes = set.union({random.randrange(0, 500) for _ in range(100)}, {random.randrange(1000, 2000) for _ in range(100)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "45a49236-979b-414e-9384-e5548a3b444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd20ab27-a0e5-4f78-9c83-7e65a8629f34",
   "metadata": {},
   "source": [
    "### experiment (en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8e3b7d2a-07fb-4f77-bd02-d17b29deac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "gec_en = gec_factory.create(model_name, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2d0022f4-fd1d-4992-aa31-bc4f946c708a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Edit the text for spelling and grammar mistakes. Do not paraphrase the text. Correct just evident mistakes. Do not explain anything. Do not change numbers to letters. Return only the corrected text. Example. Text: The modern techonlogy is better now than what it used to be. Correct text: The modern technology is better now than it used to be. Text: __TEXT_PLACEHOLDER__ Correct text: '"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gec_en.prompt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d94d3ba5-041b-4ebc-ba26-5b430342cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_en = get_examples(list(range(2191)), 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "71e74747-8ae6-48c1-9284-845447b168f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': 'correct_0.txt', 'original_text': '13th June 2000'},\n",
       " {'file_name': 'correct_1.txt', 'original_text': 'Dear Ms Helen Ryan'},\n",
       " {'file_name': 'correct_2.txt', 'original_text': 'Competition Organiser'},\n",
       " {'file_name': 'correct_3.txt',\n",
       "  'original_text': 'I am therefore writing to give you my further information.'},\n",
       " {'file_name': 'correct_4.txt',\n",
       "  'original_text': 'First of all, I am a student and would like to travel in July.'}]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_en[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a69dcb06-efb2-4b2b-835e-672410c97dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 189/189 [02:00<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "process(examples_en, gec_en, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "df17bee6-12e5-4c44-9fdb-8851a20fa7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': 'incorrect_1541.txt',\n",
       "  'original_text': 'I though she was a really good friend but I made a mistake.',\n",
       "  'corrected_text': 'I thought she was a really good friend but I made a mistake.'},\n",
       " {'file_name': 'correct_7.txt',\n",
       "  'original_text': 'Therefore I would like to choose basketball and tennis.',\n",
       "  'corrected_text': 'Therefore, I would like to choose basketball and tennis.'},\n",
       " {'file_name': 'correct_8.txt',\n",
       "  'original_text': 'I would be most grateful if you could give me further advicable information.',\n",
       "  'corrected_text': 'I would be most grateful if you could provide me with more advice.'},\n",
       " {'file_name': 'correct_10.txt',\n",
       "  'original_text': 'Yours sincerely,',\n",
       "  'corrected_text': 'Sincerely,'},\n",
       " {'file_name': 'incorrect_1034.txt',\n",
       "  'original_text': 'In my opinion it would be nice if you create an exhibition place where the guests can try to play different instruments.',\n",
       "  'corrected_text': 'In my opinion, it would be nice if you created a showcase area where guests could try playing different musical instruments.'}]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_en[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "809d5db0-2df7-4b81-a15f-da0038c4f5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 189/189 [00:00<00:00, 869.93it/s]\n"
     ]
    }
   ],
   "source": [
    "save_examples(examples_en, 'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b649c980-e089-412e-a0ba-81e41a786668",
   "metadata": {},
   "source": [
    "### Experiment (de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "873b0547-95a8-4e20-8db6-0e29603b57db",
   "metadata": {},
   "outputs": [],
   "source": [
    "gec_de = gec_factory.create(model_name, 'de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0e6afca4-bc1c-41c7-aeee-ba97c7f183d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bearbeiten Sie den Text auf Rechtschreib- und Grammatikfehler. Paraphrasieren Sie den Text nicht. Korrigieren Sie nur offensichtliche Fehler. Erklären Sie nichts. Ändern Sie keine Zahlen in Buchstaben. Geben Sie nur den korrigierten Text zurück. Beispiel. Text: Die moderne Technik ist heute besser als früher. Richtiger Text: Die moderne Technik ist heute besser als früher. Text: __TEXT_PLACEHOLDER__ Richtiger Text: '"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gec_de.prompt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3b3e0360-95ac-4509-b081-574073208ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_de = get_examples(indexes, 'de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "600ab516-9b2f-4450-b24f-886d9628bcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': 'incorrect_1541.txt',\n",
       "  'original_text': 'Viele Männer sind gegen Feminismus, weil sie Frauen ohne die Kleidung mogen, und diese Meinung ist schwer zu verändern!'},\n",
       " {'file_name': 'correct_7.txt',\n",
       "  'original_text': 'Wenn man darauf nicht vorbereitet ist, kann man nicht richtig arbeiten.'},\n",
       " {'file_name': 'correct_8.txt',\n",
       "  'original_text': 'Zum Beispiel kommt ein deutscher Professor nach Stellenbosch und kann nicht Afrikaans oder Englisch sprechen.'},\n",
       " {'file_name': 'correct_10.txt',\n",
       "  'original_text': 'Aber darauf bin ich nicht vorbereitet.'},\n",
       " {'file_name': 'incorrect_1034.txt',\n",
       "  'original_text': 'In vielen Länder der EU kommt das Ausbildungssystem oft zum Vorgrund der politischen und sozialischen Debatten.'}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_de[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "726798b0-f813-4636-9382-e125cc558660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 189/189 [02:51<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "process(examples_de, gec_de, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7055ee81-ce81-4b8c-87b3-b9f52d321c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': 'incorrect_1541.txt',\n",
       "  'original_text': 'Viele Männer sind gegen Feminismus, weil sie Frauen ohne die Kleidung mogen, und diese Meinung ist schwer zu verändern!',\n",
       "  'corrected_text': 'Viele Männer sind gegen Feminismus, weil sie Frauen ohne das Kleidungsstück mögen, und diese Meinung ist schwer zu ändern!'},\n",
       " {'file_name': 'correct_7.txt',\n",
       "  'original_text': 'Wenn man darauf nicht vorbereitet ist, kann man nicht richtig arbeiten.',\n",
       "  'corrected_text': 'Wenn man sich nicht darauf vorbereitet hat, kann man nicht richtig arbeiten.'},\n",
       " {'file_name': 'correct_8.txt',\n",
       "  'original_text': 'Zum Beispiel kommt ein deutscher Professor nach Stellenbosch und kann nicht Afrikaans oder Englisch sprechen.',\n",
       "  'corrected_text': 'Zum Beispiel kommt ein deutscher Professor nach Stellenbosch und kann weder Afrikaans noch Englisch sprechen.'},\n",
       " {'file_name': 'correct_10.txt',\n",
       "  'original_text': 'Aber darauf bin ich nicht vorbereitet.',\n",
       "  'corrected_text': 'Aber darauf warte ich nicht.'},\n",
       " {'file_name': 'incorrect_1034.txt',\n",
       "  'original_text': 'In vielen Länder der EU kommt das Ausbildungssystem oft zum Vorgrund der politischen und sozialischen Debatten.',\n",
       "  'corrected_text': 'In vielen Ländern der EU steht die Bildung häufig im Mittelpunkt politischer und gesellschaftlicher Debatten.'}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_de[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "60ed5d2f-8b9e-4aca-948b-a396f3f8ea97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 189/189 [00:00<00:00, 11960.76it/s]\n"
     ]
    }
   ],
   "source": [
    "save_examples(examples_de, 'de')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solarski",
   "language": "python",
   "name": "solarski"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
