{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "380580f1-a450-40c8-b438-1e56245bf78c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "28fd458b-709f-4b5c-8a69-effd49e047b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTS = {\n",
    "    \"en\": \"Edit the text for spelling and grammar mistakes. \" \\\n",
    "               + \"Do not paraphrase the text. Correct just evident mistakes. Do not explain anything. \" \\\n",
    "               + \"Do not change numbers to letters. Return only the corrected text. \" \\\n",
    "               + \"Example. Text: The modern techonlogy is better now than what it used to be. \" \\\n",
    "               + \"Correct text: The modern technology is better now than it used to be. \" \\\n",
    "               + \"Text: __TEXT_PLACEHOLDER__ Correct text: \",\n",
    "    \"de\": \"Bearbeiten Sie den Text auf Rechtschreib- und Grammatikfehler. \" \\\n",
    "               + \"Paraphrasieren Sie den Text nicht. Korrigieren Sie nur offensichtliche Fehler. Erklären Sie nichts. \" \\\n",
    "               + \"Ändern Sie keine Zahlen in Buchstaben. Geben Sie nur den korrigierten Text zurück. \" \\\n",
    "               + \"Beispiel. Text: Die modere Technik ist heute als besser früher. \" \\\n",
    "               + \"Richtiger Text: Die moderne Technik ist heute besser als früher. \" \\\n",
    "               + \"Text: __TEXT_PLACEHOLDER__ Richtiger Text: \"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5d5ff7e5-272e-4b70-bf69-f8574c74262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModelGec:\n",
    "\n",
    "    def __init__(self, p, lang):\n",
    "        self.text_generation_pipeline = p\n",
    "        self.prompt_text = PROMPTS[lang]\n",
    "\n",
    "    def get_conversation_template(self, prompt):\n",
    "        return [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def get_prompt(self, text):\n",
    "        return self.prompt_text.replace(\"__TEXT_PLACEHOLDER__\", text)\n",
    "\n",
    "    def __call__(self, text, params, debug=False):\n",
    "        prompt = self.get_prompt(text)\n",
    "        messages = self.get_conversation_template(prompt)\n",
    "        inputs = self.text_generation_pipeline.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        outputs = self.text_generation_pipeline(inputs, **params)\n",
    "        if debug:\n",
    "            print(messages)\n",
    "            print()\n",
    "            print(inputs)\n",
    "            print()\n",
    "            print(outputs)\n",
    "            print()\n",
    "        return outputs[0][\"generated_text\"].lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2802d17a-d106-4d2e-98d0-c6e7d5bbd17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModelGecFactory:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model_cache = {}\n",
    "\n",
    "    def get_pipeline(self, model_name, torch_dtype, device):\n",
    "        if model_name in self.model_cache:\n",
    "            return self.model_cache[model_name]\n",
    "        else:\n",
    "            p = pipeline(\n",
    "                \"text-generation\", \n",
    "                model=model_name,\n",
    "                torch_dtype=torch_dtype,\n",
    "                device=device,\n",
    "            )\n",
    "            self.model_cache[model_name] = p\n",
    "            return p\n",
    "\n",
    "    def create(self, model_name, lang, torch_dtype=torch.bfloat16, device='cuda'):\n",
    "        p = self.get_pipeline(model_name, torch_dtype, device)\n",
    "        return LanguageModelGec(p, lang)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cce2a14-d186-4d42-9559-2bb4bb1cf54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gec_factory = LanguageModelGecFactory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b6955a6b-2afc-469b-ab31-eca747eea95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Unbabel/TowerInstruct-7B-v0.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "70596df4-7925-4cd1-9ad3-73f5cc7080b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LanguageModelGec at 0x7984363036d0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gec_factory.create(model_name, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a8d91881-ea3a-4068-a124-bc2385a7e20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unbabel/TowerInstruct-7B-v0.2': <transformers.pipelines.text_generation.TextGenerationPipeline at 0x7987a7e0d970>}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gec_factory.model_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c428244-15fc-4788-8481-d7de20444e48",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d0367dc7-5e0b-461c-9797-22492d2eab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"do_sample\": True,\n",
    "    \"repetition_penalty\": 1.18,\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"top_k\": 40,\n",
    "    \"top_p\": 0.1,\n",
    "    \"temperature\": 0.1,\n",
    "    \"return_full_text\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1a4d69-423d-433b-bc62-292253b8bb31",
   "metadata": {},
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74ce5246-209e-43e6-b479-203717eadd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "gec = gec_factory.create(model_name, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c3b6d077-adde-491a-8ca3-b63921cfb53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Edit the text for spelling and grammar mistakes. Do not paraphrase the text. Correct just evident mistakes. Do not explain anything. Do not change numbers to letters. Return only the corrected text. Example. Text: The modern techonlogy is better now than what it used to be. Correct text: The modern technology is better now than it used to be. Text: It became scencial to do my homework. Correct text: '}]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = gec.get_conversation_template(gec.get_prompt(\"It became scencial to do my homework.\"))\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "725929aa-56f4-497a-9d80-d1c18bd4766e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Edit the text for spelling and grammar mistakes. Do not paraphrase the text. Correct just evident mistakes. Do not explain anything. Do not change numbers to letters. Return only the corrected text. Example. Text: The modern techonlogy is better now than what it used to be. Correct text: The modern technology is better now than it used to be. Text: It became scencial to do my homework. Correct text: <|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = gec.text_generation_pipeline.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd6e132e-71cd-482c-8834-010c63656ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = gec.text_generation_pipeline(inputs, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "009d608a-8f6a-44a3-b0cf-2e8827758e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': ' It has become essential to do my homework.'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fcbde69-120d-4214-8410-0a82f532f136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It has become essential to do my homework.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gec(\"It became scencial to do my homework.\", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fd205d-6022-492f-b068-07a1ec8325eb",
   "metadata": {},
   "source": [
    "### Experiments set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1b0bb808-468d-4957-9c4d-460b49473dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"geceval/data/raw/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "df2b26da-5a70-4ff1-9585-5a4462032217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(idx, lang):\n",
    "    base_path = DATA_PATH + lang + \"/\"\n",
    "    file_name = f\"correct_{idx}.txt\"\n",
    "    if os.path.exists(base_path + file_name):\n",
    "        with open(base_path + file_name) as f:\n",
    "            return file_name, f.read()\n",
    "    else:\n",
    "        file_name = \"in\" + file_name\n",
    "        with open(base_path + file_name) as f:\n",
    "            return file_name, f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ec2c4080-1ebc-4e5d-8bd8-752283c453bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_single_example(idx, lang):\n",
    "    file_name, file_content = read_text(idx, lang)\n",
    "    return {\n",
    "        \"file_name\": file_name,\n",
    "        \"original_text\": file_content,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a7819b7e-03f4-4ba8-a70a-c06027b734c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_examples(idxes, lang):\n",
    "    examples = []\n",
    "    for i in idxes:\n",
    "        examples.append(prepare_single_example(i, lang))\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ff026985-4134-4fd9-b97e-dd3c164ec720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(examples, gec, params):\n",
    "    for example in tqdm(examples):\n",
    "        if \"corrected_text\" not in example:\n",
    "            text = example[\"original_text\"]\n",
    "            example[\"corrected_text\"] = gec(text, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "07dd427c-ca0d-4e93-bf2a-d94f97d955a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_examples(examples, lang):\n",
    "    base_path = DATA_PATH + lang + \"/\"\n",
    "    for example in tqdm(examples):\n",
    "        file_name = example[\"file_name\"]\n",
    "        inference_file_name = example[\"file_name\"].replace(\".txt\", \"\") + \"_inference.txt\"\n",
    "        original_text = example[\"original_text\"]\n",
    "        corrected_text = example[\"corrected_text\"]\n",
    "\n",
    "        if not os.path.exists(base_path + file_name):\n",
    "            with open(base_path + file_name, 'w') as f:\n",
    "                f.write(original_text)\n",
    "        if not os.path.exists(base_path + inference_file_name):\n",
    "            with open(base_path + inference_file_name, 'w') as f:\n",
    "                f.write(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "10741381-1b8c-44d9-a5df-18bb9586870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# random.seed(23)\n",
    "# indexes = set.union({random.randrange(0, 500) for _ in range(100)}, {random.randrange(1000, 2000) for _ in range(100)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "45a49236-979b-414e-9384-e5548a3b444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd20ab27-a0e5-4f78-9c83-7e65a8629f34",
   "metadata": {},
   "source": [
    "### experiment (en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8e3b7d2a-07fb-4f77-bd02-d17b29deac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "gec_en = gec_factory.create(model_name, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2d0022f4-fd1d-4992-aa31-bc4f946c708a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Edit the text for spelling and grammar mistakes. Do not paraphrase the text. Correct just evident mistakes. Do not explain anything. Do not change numbers to letters. Return only the corrected text. Example. Text: The modern techonlogy is better now than what it used to be. Correct text: The modern technology is better now than it used to be. Text: __TEXT_PLACEHOLDER__ Correct text: '"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gec_en.prompt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d94d3ba5-041b-4ebc-ba26-5b430342cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_en = get_examples(list(range(2191)), 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "71e74747-8ae6-48c1-9284-845447b168f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': 'correct_0.txt', 'original_text': '13th June 2000'},\n",
       " {'file_name': 'correct_1.txt', 'original_text': 'Dear Ms Helen Ryan'},\n",
       " {'file_name': 'correct_2.txt', 'original_text': 'Competition Organiser'},\n",
       " {'file_name': 'correct_3.txt',\n",
       "  'original_text': 'I am therefore writing to give you my further information.'},\n",
       " {'file_name': 'correct_4.txt',\n",
       "  'original_text': 'First of all, I am a student and would like to travel in July.'}]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_en[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a69dcb06-efb2-4b2b-835e-672410c97dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 2191/2191 [23:56<00:00,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "process(examples_en, gec_en, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "df17bee6-12e5-4c44-9fdb-8851a20fa7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': 'correct_0.txt',\n",
       "  'original_text': '13th June 2000',\n",
       "  'corrected_text': 'Thirteenth June 2000'},\n",
       " {'file_name': 'correct_1.txt',\n",
       "  'original_text': 'Dear Ms Helen Ryan',\n",
       "  'corrected_text': 'Dear Ms Helen Ryan'},\n",
       " {'file_name': 'correct_2.txt',\n",
       "  'original_text': 'Competition Organiser',\n",
       "  'corrected_text': 'Competition organizer'},\n",
       " {'file_name': 'correct_3.txt',\n",
       "  'original_text': 'I am therefore writing to give you my further information.',\n",
       "  'corrected_text': 'I am therefore writing to provide you with more information.'},\n",
       " {'file_name': 'correct_4.txt',\n",
       "  'original_text': 'First of all, I am a student and would like to travel in July.',\n",
       "  'corrected_text': 'First of all, I am a student and would like to travel in July.'}]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_en[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "809d5db0-2df7-4b81-a15f-da0038c4f5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 2191/2191 [00:01<00:00, 1140.63it/s]\n"
     ]
    }
   ],
   "source": [
    "save_examples(examples_en, 'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b649c980-e089-412e-a0ba-81e41a786668",
   "metadata": {},
   "source": [
    "### Experiment (de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "572ee5f9-bfc7-4357-a063-d400c5a8e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = {random.randrange(0, 2503) for _ in range(100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "873b0547-95a8-4e20-8db6-0e29603b57db",
   "metadata": {},
   "outputs": [],
   "source": [
    "gec_de = gec_factory.create(model_name, 'de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0e6afca4-bc1c-41c7-aeee-ba97c7f183d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bearbeiten Sie den Text auf Rechtschreib- und Grammatikfehler. Paraphrasieren Sie den Text nicht. Korrigieren Sie nur offensichtliche Fehler. Erklären Sie nichts. Ändern Sie keine Zahlen in Buchstaben. Geben Sie nur den korrigierten Text zurück. Beispiel. Text: Die modere Technik ist heute als besser früher. Richtiger Text: Die moderne Technik ist heute besser als früher. Text: __TEXT_PLACEHOLDER__ Richtiger Text: '"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gec_de.prompt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3b3e0360-95ac-4509-b081-574073208ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_de = get_examples(indexes, 'de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "600ab516-9b2f-4450-b24f-886d9628bcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': 'incorrect_1544.txt',\n",
       "  'original_text': 'Auch, zahlen viele Frauen weniger als Männer.'},\n",
       " {'file_name': 'incorrect_1545.txt',\n",
       "  'original_text': 'Den Interessen der Frauen hat, seit die achtzehnten jahrhundert, verändert, zum Beispiel, viele Frauen wollen arbeiten statt eine Familie haben und Feminismus hat dieser Interessen erkennen.'},\n",
       " {'file_name': 'incorrect_2058.txt',\n",
       "  'original_text': 'Viele, liebe Gruße Deine Freundin'},\n",
       " {'file_name': 'correct_16.txt',\n",
       "  'original_text': 'Bei uns in Vietnam ist die soziale Leistung nicht so gut wie in Deutschland.'},\n",
       " {'file_name': 'incorrect_1046.txt',\n",
       "  'original_text': 'Außerdem, führen die Universitätskursen allmählich den praktischen Element ein - Beispiele davon sind das oft notwendige Jahr im Ausland für Fremdsprachenstudien, oder Jahren im Betrieb für künftige Ärzte, Rechtsanwälter und Ingenieuren.'}]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_de[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726798b0-f813-4636-9382-e125cc558660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████████████▉   | 97/100 [01:24<00:02,  1.36it/s]"
     ]
    }
   ],
   "source": [
    "process(examples_de, gec_de, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7055ee81-ce81-4b8c-87b3-b9f52d321c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_de[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ed5d2f-8b9e-4aca-948b-a396f3f8ea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_examples(examples_de, 'de')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solarski",
   "language": "python",
   "name": "solarski"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
